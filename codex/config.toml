# see https://developers.openai.com/codex/local-config#cli
model = "gpt-5.3-codex"
model_reasoning_effort = "medium"
model_reasoning_summary = "detailed"
# read-only | workspace-write | danger-full-access
sandbox_mode = "danger-full-access"
approval_policy = "never"
tool_output_token_limit = 25000
model_auto_compact_token_limit = 233000
personality = "pragmatic"
web_search = "live"

[notice]
"hide_gpt-5.1-codex-max_migration_prompt" = true

[notice.model_migrations]
"gpt-5.2" = "gpt-5.2-codex"
"gpt-5.1-codex-mini" = "gpt-5.2-codex"

[features]
rmcp_client = true
skills = true
skill_snapshot = true
apply_patch_freeform = true
ghost_commit = false
unified_exec = true
shell_snapshot = true
steer = true
collab = true

[mcp_servers.nowledge-mem]
url = "http://127.0.0.1:14242/mcp/"
startup_timeout_sec = 30
tool_timeout_sec = 45

[mcp_servers.nowledge-mem.http_headers]
APP = "Codex"

[projects."/Users/tizee/projects/project-conf/dotfiles/tizee-dotfiles"]
trust_level = "untrusted"
