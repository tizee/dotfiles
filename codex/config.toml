# see https://developers.openai.com/codex/local-config#cli
model = "gpt-5.2-codex"
model_reasoning_effort = "high"
model_reasoning_summary = "detailed"
# read-only | workspace-write | danger-full-access
sandbox_mode = "danger-full-access"
approval_policy = "never"


[notice]
"hide_gpt-5.1-codex-max_migration_prompt" = true

[notice.model_migrations]
"gpt-5.2" = "gpt-5.2-codex"

[features]
rmcp_client = true
skills = true
web_search_request = true
unified_exec = true
shell_snapshot = true

[mcp_servers.nowledge-mem]
url = "http://127.0.0.1:14242/mcp/"
startup_timeout_sec = 30
tool_timeout_sec = 45

[mcp_servers.nowledge-mem.http_headers]
APP = "Codex"

[projects."/Users/tizee/projects/project-conf/dotfiles/tizee-dotfiles"]
trust_level = "untrusted"
